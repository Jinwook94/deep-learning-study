{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H(x) = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "# 여기서 variable은 tensorflow가 사용하는 값이라고 볼 수 있다.\n",
    "# 또는 trainable 한 값이라고 봐도 무방하다.\n",
    "# variable을 만들때는 shape을 정의하고 값을 준다. \n",
    "# 따라서 W,b의 값을 모르기때문에 랜덤값을 주게되는데, 이를위해 random_normal 함수를 사용한다.\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# W와 b 값이 정의 되었으므로 linear regression의 수식으로 hypothesis는 우리의 node가된다.\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf는 square라는 제곱 함수를 제공해준다.\n",
    "# reduce_mean은 어떠한 텐서가 주어졌을때 평균을 내주는 함수이다\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce_mean의 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [1.,2.,3.,4.]\n",
    "# 결과값은 2.5가 된다\n",
    "tf.reduce_mean(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우에는 옵티마이저를 정의하는 여러가지 방법이 있는데 현재는 우선 GradientDescentOptimizer를 사용.\n",
    "# 옵티마이저 정의 부분은 추후에 설명한다.\n",
    "# minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run/update graph and get result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.09917677] 0.42745006 [0.36193833] [0.8811108]\n",
      "20 [0.3967554] 0.12609933 [0.5719314] [0.9188871]\n",
      "40 [1.1025864] 0.11214892 [0.6091892] [0.88324267]\n",
      "60 [-0.85240626] 0.10183386 [0.6291879] [0.8424515]\n",
      "80 [0.9068368] 0.092486955 [0.64677024] [0.8029277]\n",
      "100 [0.8994751] 0.083998166 [0.66338545] [0.76519954]\n",
      "120 [-0.65663165] 0.07628845 [0.6792065] [0.72923857]\n",
      "140 [-0.78952914] 0.069286376 [0.6942827] [0.69496715]\n",
      "160 [-0.8146077] 0.06292705 [0.7086503] [0.6623063]\n",
      "180 [-1.0433455] 0.057151336 [0.7223426] [0.63118035]\n",
      "200 [-0.7059975] 0.05190577 [0.7353915] [0.6015172]\n",
      "220 [1.4074525] 0.047141656 [0.7478272] [0.5732482]\n",
      "240 [0.20769002] 0.04281479 [0.75967836] [0.5463076]\n",
      "260 [0.6633994] 0.038885105 [0.77097255] [0.5206333]\n",
      "280 [-0.7221536] 0.03531606 [0.78173596] [0.49616545]\n",
      "300 [0.8834586] 0.03207462 [0.7919936] [0.4728475]\n",
      "320 [0.47090757] 0.029130703 [0.80176914] [0.4506254]\n",
      "340 [-1.5521514] 0.026456976 [0.81108516] [0.42944768]\n",
      "360 [-0.7516207] 0.024028622 [0.8199635] [0.40926522]\n",
      "380 [-1.8355926] 0.021823162 [0.8284246] [0.39003122]\n",
      "400 [-0.5879553] 0.019820156 [0.836488] [0.37170115]\n",
      "420 [0.29424167] 0.018000988 [0.8441725] [0.35423255]\n",
      "440 [-1.0203214] 0.016348757 [0.85149586] [0.33758485]\n",
      "460 [0.532769] 0.01484821 [0.858475] [0.32171953]\n",
      "480 [0.695548] 0.013485373 [0.86512625] [0.30659986]\n",
      "500 [-0.9181081] 0.0122476285 [0.8714648] [0.29219076]\n",
      "520 [-0.7724027] 0.011123508 [0.87750536] [0.27845892]\n",
      "540 [1.1834286] 0.010102545 [0.8832622] [0.26537237]\n",
      "560 [-1.851133] 0.009175306 [0.8887484] [0.25290093]\n",
      "580 [0.49852985] 0.008333161 [0.89397687] [0.24101548]\n",
      "600 [-0.8001575] 0.0075683123 [0.8989596] [0.22968867]\n",
      "620 [-2.3631754] 0.0068736444 [0.9037081] [0.21889414]\n",
      "640 [0.15035951] 0.0062427656 [0.9082334] [0.20860696]\n",
      "660 [1.9627053] 0.0056697875 [0.9125461] [0.19880325]\n",
      "680 [0.2914461] 0.005149384 [0.91665614] [0.18946023]\n",
      "700 [-2.7446551] 0.004676765 [0.92057294] [0.18055634]\n",
      "720 [0.6906624] 0.0042475048 [0.9243057] [0.17207089]\n",
      "740 [-1.6121186] 0.0038576573 [0.927863] [0.1639842]\n",
      "760 [0.6428439] 0.0035035815 [0.93125325] [0.15627755]\n",
      "780 [-0.03925992] 0.0031820114 [0.9344841] [0.14893305]\n",
      "800 [-0.24707425] 0.0028899538 [0.93756306] [0.14193375]\n",
      "820 [-1.1700032] 0.0026247036 [0.9404974] [0.13526341]\n",
      "840 [1.6478658] 0.0023837953 [0.9432938] [0.12890655]\n",
      "860 [0.2193834] 0.0021650034 [0.9459588] [0.12284841]\n",
      "880 [-0.1680913] 0.001966296 [0.9484984] [0.11707499]\n",
      "900 [-1.1759242] 0.0017858171 [0.95091885] [0.11157292]\n",
      "920 [-2.1887434] 0.0016219063 [0.95322555] [0.10632941]\n",
      "940 [0.696457] 0.0014730431 [0.9554238] [0.10133232]\n",
      "960 [-1.4523916] 0.0013378417 [0.95751864] [0.09657006]\n",
      "980 [1.0249997] 0.0012150432 [0.9595152] [0.09203164]\n",
      "1000 [-0.5088338] 0.001103522 [0.9614178] [0.08770645]\n",
      "1020 [0.7808239] 0.0010022428 [0.963231] [0.08358456]\n",
      "1040 [0.6790577] 0.00091025134 [0.964959] [0.07965638]\n",
      "1060 [-1.1491865] 0.00082670065 [0.9666058] [0.07591285]\n",
      "1080 [-0.96522456] 0.0007508229 [0.96817523] [0.07234523]\n",
      "1100 [-1.2258302] 0.0006819119 [0.9696708] [0.06894531]\n",
      "1120 [1.4411787] 0.0006193258 [0.9710962] [0.06570515]\n",
      "1140 [0.05004665] 0.0005624785 [0.97245455] [0.06261722]\n",
      "1160 [0.13720873] 0.00051085296 [0.9737491] [0.05967445]\n",
      "1180 [-1.7696078] 0.00046396288 [0.9749828] [0.05686995]\n",
      "1200 [-2.7268205] 0.0004213796 [0.97615856] [0.05419727]\n",
      "1220 [0.4782368] 0.00038270303 [0.977279] [0.05165018]\n",
      "1240 [-0.06853548] 0.00034757913 [0.97834677] [0.04922282]\n",
      "1260 [2.568796] 0.00031567836 [0.9793643] [0.04690957]\n",
      "1280 [-0.50866646] 0.00028670323 [0.9803343] [0.04470501]\n",
      "1300 [-0.17637931] 0.00026038793 [0.98125845] [0.04260403]\n",
      "1320 [2.329961] 0.00023648662 [0.9821392] [0.04060178]\n",
      "1340 [0.34250915] 0.0002147807 [0.98297864] [0.03869363]\n",
      "1360 [0.24028857] 0.00019506658 [0.9837786] [0.03687515]\n",
      "1380 [-1.9511356] 0.0001771644 [0.98454094] [0.03514214]\n",
      "1400 [0.43134844] 0.00016090227 [0.98526746] [0.03349056]\n",
      "1420 [-0.8174269] 0.00014613524 [0.9859598] [0.03191663]\n",
      "1440 [-0.27221617] 0.00013272179 [0.98661965] [0.03041667]\n",
      "1460 [0.13955195] 0.00012053908 [0.98724854] [0.0289872]\n",
      "1480 [1.3707715] 0.00010947738 [0.98784775] [0.02762488]\n",
      "1500 [-0.12017235] 9.94286e-05 [0.9884188] [0.02632662]\n",
      "1520 [0.8281535] 9.030284e-05 [0.98896307] [0.0250894]\n",
      "1540 [0.09278935] 8.2014514e-05 [0.9894817] [0.02391031]\n",
      "1560 [0.59134966] 7.4488256e-05 [0.98997587] [0.02278674]\n",
      "1580 [0.11429011] 6.765042e-05 [0.9904472] [0.02171585]\n",
      "1600 [-0.8312236] 6.144198e-05 [0.99089617] [0.02069527]\n",
      "1620 [0.47981808] 5.5801313e-05 [0.991324] [0.01972264]\n",
      "1640 [2.2794752] 5.067958e-05 [0.99173176] [0.01879573]\n",
      "1660 [1.7173569] 4.6027624e-05 [0.9921203] [0.01791239]\n",
      "1680 [0.76688176] 4.180401e-05 [0.99249065] [0.01707055]\n",
      "1700 [-1.5754131] 3.796708e-05 [0.9928435] [0.01626831]\n",
      "1720 [-2.0948288] 3.448187e-05 [0.99317986] [0.01550379]\n",
      "1740 [-0.93369013] 3.1317348e-05 [0.9935004] [0.01477516]\n",
      "1760 [-0.6417046] 2.8443423e-05 [0.9938058] [0.01408077]\n",
      "1780 [-0.37425336] 2.5832365e-05 [0.99409693] [0.01341904]\n",
      "1800 [-0.8523444] 2.3461165e-05 [0.9943744] [0.01278838]\n",
      "1820 [-0.18019566] 2.130764e-05 [0.99463874] [0.01218737]\n",
      "1840 [-0.29604453] 1.9352165e-05 [0.99489075] [0.01161459]\n",
      "1860 [-0.28680405] 1.7575769e-05 [0.9951309] [0.01106871]\n",
      "1880 [1.0045184] 1.5962236e-05 [0.9953597] [0.01054852]\n",
      "1900 [1.09073] 1.4497612e-05 [0.9955778] [0.01005277]\n",
      "1920 [0.7569878] 1.316715e-05 [0.9957856] [0.00958032]\n",
      "1940 [0.78450507] 1.1958279e-05 [0.99598366] [0.00913008]\n",
      "1960 [-0.5989349] 1.0860479e-05 [0.9961724] [0.00870101]\n",
      "1980 [1.2305793] 9.863491e-06 [0.9963523] [0.00829209]\n",
      "2000 [-0.92427176] 8.9587e-06 [0.99652374] [0.00790239]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# 우리는 W,b라는 variable을 사용했기때문에 global_variables_initializer를 사용해줘야한다\n",
    "# global_variables_initializer를 사용하면 변수를 initialize한다\n",
    "# Initializes global varialbes in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the Line\n",
    "for step in range(2001):\n",
    "    # node 실행\n",
    "    sess.run(train)\n",
    "    # 20번에 한번 꼴로 값들을 출력\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(tf.random_normal([1])), sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
